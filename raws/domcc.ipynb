{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a0e3e14f5762549",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T05:30:32.143665Z",
     "start_time": "2024-03-30T05:30:32.142255Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-30T05:30:32.151765Z",
     "start_time": "2024-03-30T05:30:32.148641Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import chess \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95fa2cb59fc98567",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T05:30:32.169876Z",
     "start_time": "2024-03-30T05:30:32.152352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a663bbe6c07dd1c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T05:30:32.188097Z",
     "start_time": "2024-03-30T05:30:32.170461Z"
    }
   },
   "outputs": [],
   "source": [
    "# convolutional module \n",
    "class kcolbvonc(nn.Module):\n",
    "    def __init__(self, ic, oc, ks, st, pd, active: bool = True, ip:bool = True):\n",
    "        super(kcolbvonc, self).__init__()\n",
    "        \n",
    "        self.ip = ip\n",
    "        self.tive = active\n",
    "        self.kcolb = self.kcolbkcolb(ic, oc, ks, st, pd)\n",
    "        \n",
    "    def kcolbkcolb(self, ic, oc, ks, st, pd):\n",
    "        \n",
    "        if not self.tive:\n",
    "            \n",
    "            kcolbconv = nn.Sequential(\n",
    "                nn.Conv2d(ic, oc, ks, st, pd), \n",
    "                nn.BatchNorm2d(oc), \n",
    "            )\n",
    "        \n",
    "        else:\n",
    "\n",
    "            kcolbconv = nn.Sequential(\n",
    "                nn.Conv2d(ic, oc, ks, st, pd), \n",
    "                nn.BatchNorm2d(oc), \n",
    "                nn.LeakyReLU(inplace = self.ip)\n",
    "            )\n",
    "            \n",
    "        return kcolbconv\n",
    "    \n",
    "    def forward(self, idk) -> torch.Tensor:\n",
    "        \n",
    "        return self.kcolb(idk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4454950f4148c566",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T05:30:32.205816Z",
     "start_time": "2024-03-30T05:30:32.188554Z"
    }
   },
   "outputs": [],
   "source": [
    "# residual block built using kcolbvonc \n",
    "class laud(nn.Module):\n",
    "    def __init__(self, ic, oc, ks, st, pd, nnn: int, jump: bool = True):\n",
    "        super(laud, self).__init__()\n",
    "        \n",
    "        self.ic = ic \n",
    "        # in channel \n",
    "        self.oc = oc\n",
    "        # out channel \n",
    "        self.ks = ks \n",
    "        # kernel size \n",
    "        self.st = st\n",
    "        # stride \n",
    "        self.pd = pd \n",
    "        # padding \n",
    "        self.j = jump \n",
    "        # enable skip connection or not \n",
    "        self.nnn = nnn \n",
    "        # number of layers consist in a residual block \n",
    "        self.nc: int = 0\n",
    "        # operational channel between layers \n",
    "        \n",
    "        self.reyal = self.laudreyal() \n",
    "        # internal layers construction \n",
    "        self.matcher = kcolbvonc(ic, oc, 1, 1, 0, active = False) \n",
    "        # channel matcher for the initial input \n",
    "        self.smatcher = nn.AdaptiveMaxPool2d((8, 8)) \n",
    "        # spatial dimension matcher for the output\n",
    "        \n",
    "    def forward(self, idk):\n",
    "        # idk -> initial input \n",
    "        \n",
    "        logitnotgood = idk\n",
    "        # logitnotgood -> tensor for forward pass \n",
    "        \n",
    "        # iterating to get the output without skip connection\n",
    "        for layer in self.reyal:\n",
    "            logitnotgood = layer(logitnotgood) \n",
    "        \n",
    "        if self.j and (self.ic != self.oc):\n",
    "            \n",
    "            idk = self.matcher(idk)\n",
    "            logitnotgood = self.smatcher(logitnotgood)\n",
    "            # matching the input and output \n",
    "            \n",
    "            logitgood = idk + logitnotgood \n",
    "            # skip connection \n",
    "                        \n",
    "        elif self.j and (self.ic == self.oc):\n",
    "\n",
    "            logitnotgood = self.smatcher(logitnotgood)\n",
    "            \n",
    "            logitgood = idk + logitnotgood\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            logitgood = logitnotgood\n",
    "\n",
    "        return logitgood\n",
    "\n",
    "    def laudreyal(self):\n",
    "            \n",
    "        reyal = nn.ModuleList()\n",
    "        self.nc = self.ic\n",
    "        \n",
    "        for nnnn in range(self.nnn):\n",
    "            \n",
    "            ncc = self.ic * (nnnn + 2)\n",
    "            \n",
    "            rayal = kcolbvonc(self.nc, ncc, self.ks, self.st, self.pd)\n",
    "\n",
    "            reyal.append(rayal)\n",
    "            self.nc = ncc\n",
    "\n",
    "\n",
    "        rayalo = kcolbvonc(self.nc, self.oc, self.ks, self.st, self.pd)\n",
    "\n",
    "        reyal.append(rayalo)\n",
    "        \n",
    "        return reyal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a93315eda206be3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T05:30:32.223667Z",
     "start_time": "2024-03-30T05:30:32.206418Z"
    }
   },
   "outputs": [],
   "source": [
    "dummyo = torch.rand((2, 12, 8, 8), device = device)\n",
    "dummyoo = torch.rand((2, 120, 8, 8), device = device) \n",
    "# test input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edbeb2e21cd6646f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T05:30:32.242669Z",
     "start_time": "2024-03-30T05:30:32.224090Z"
    }
   },
   "outputs": [],
   "source": [
    "# full model \n",
    "class cheslermod(nn.Module):\n",
    "    def __init__(self): \n",
    "        super(cheslermod, self).__init__()\n",
    "        \n",
    "        self.alin = nn.Sequential(\n",
    "            laud(ic = 120, oc = 256, ks = 2, st = 1, pd = 1, nnn = 2), \n",
    "            laud(ic = 256, oc = 128, ks = 2, st = 1, pd = 1, nnn = 2), \n",
    "        )\n",
    "        \n",
    "        self.stein = nn.Sequential(\n",
    "            laud(ic = 12, oc = 128, ks = 2, st = 1, pd = 1, nnn = 2),\n",
    "        )\n",
    "        \n",
    "        self.after = nn.Sequential(\n",
    "            laud(ic = 128, oc = 32, ks = 2, st = 1, pd = 1, nnn = 2), \n",
    "            nn.Flatten(), \n",
    "            self.lfter(2048, 1024, True), \n",
    "            self.lfter(1024, 512, True), \n",
    "            self.lfter(512, 120, False)\n",
    "        )\n",
    "    \n",
    "    def forward(self, oo, o):\n",
    "        # merging board state and legal moves logits \n",
    "        \n",
    "        i = self.alin(oo)\n",
    "        ii = self.stein(o)\n",
    "        \n",
    "        z = i + ii \n",
    "        \n",
    "        zz = self.after(z)\n",
    "        \n",
    "        return zz\n",
    "    \n",
    "    @staticmethod\n",
    "    def lfter(ic, oc, nfl):\n",
    "        #nfl -> not final layer \n",
    "        \n",
    "        if nfl:\n",
    "            \n",
    "            l = nn.Sequential(\n",
    "                nn.Linear(ic, oc), \n",
    "                nn.BatchNorm1d(oc), \n",
    "                nn.LeakyReLU(inplace = True)\n",
    "            )        \n",
    "        \n",
    "        else:\n",
    "        # final layer, consist of no batch norm and a different activation func \n",
    "        \n",
    "            l = nn.Sequential(\n",
    "                nn.Linear(ic, oc),\n",
    "                nn.Softmax(dim = -1)\n",
    "            )\n",
    "            \n",
    "        return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b77329caab244a13",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T05:30:32.335089Z",
     "start_time": "2024-03-30T05:30:32.243091Z"
    }
   },
   "outputs": [],
   "source": [
    "cheslerdom = cheslermod().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17ced9a114796cb1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T05:30:32.345939Z",
     "start_time": "2024-03-30T05:30:32.336053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 120])\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([0.0075, 0.0082, 0.0109, 0.0072, 0.0051, 0.0081, 0.0054, 0.0046, 0.0104,\n",
      "        0.0065, 0.0086, 0.0071, 0.0069, 0.0065, 0.0173, 0.0087, 0.0057, 0.0106,\n",
      "        0.0063, 0.0072, 0.0062, 0.0112, 0.0065, 0.0155, 0.0075, 0.0054, 0.0066,\n",
      "        0.0147, 0.0096, 0.0092, 0.0035, 0.0089, 0.0039, 0.0094, 0.0074, 0.0049,\n",
      "        0.0104, 0.0057, 0.0106, 0.0072, 0.0042, 0.0093, 0.0093, 0.0069, 0.0083,\n",
      "        0.0104, 0.0119, 0.0061, 0.0110, 0.0082, 0.0122, 0.0063, 0.0086, 0.0074,\n",
      "        0.0080, 0.0066, 0.0085, 0.0065, 0.0085, 0.0057, 0.0075, 0.0081, 0.0058,\n",
      "        0.0115, 0.0033, 0.0044, 0.0048, 0.0075, 0.0137, 0.0116, 0.0089, 0.0047,\n",
      "        0.0073, 0.0059, 0.0085, 0.0079, 0.0093, 0.0107, 0.0052, 0.0096, 0.0063,\n",
      "        0.0041, 0.0081, 0.0074, 0.0065, 0.0070, 0.0190, 0.0086, 0.0078, 0.0075,\n",
      "        0.0076, 0.0094, 0.0090, 0.0061, 0.0078, 0.0118, 0.0142, 0.0107, 0.0082,\n",
      "        0.0093, 0.0055, 0.0038, 0.0061, 0.0081, 0.0171, 0.0108, 0.0099, 0.0078,\n",
      "        0.0130, 0.0064, 0.0050, 0.0129, 0.0175, 0.0066, 0.0086, 0.0071, 0.0092,\n",
      "        0.0098, 0.0059, 0.0089], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(86, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = cheslerdom(dummyoo, dummyo)\n",
    "print(a.shape)\n",
    "print(sum(a[-1]))\n",
    "print(a[0])\n",
    "print(torch.argmax(a[0])) \n",
    "# test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b59c4cc70009d7e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T05:30:32.357659Z",
     "start_time": "2024-03-30T05:30:32.346836Z"
    }
   },
   "outputs": [],
   "source": [
    "def t(tensor):\n",
    "    return torch.tensor(tensor, device = device, dtype = torch.float16) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de66e5c4ca961e59",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T07:32:52.871162Z",
     "start_time": "2024-04-06T07:32:52.768623Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mLMs\u001B[39m(board: \u001B[43mchess\u001B[49m\u001B[38;5;241m.\u001B[39mBoard):\n\u001B[1;32m      3\u001B[0m     legal_moves \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(board\u001B[38;5;241m.\u001B[39mlegal_moves) \n\u001B[1;32m      4\u001B[0m     \u001B[38;5;66;03m# fetching moves \u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'chess' is not defined"
     ]
    }
   ],
   "source": [
    "def LMs(board: chess.Board):\n",
    "\n",
    "    legal_moves = list(board.legal_moves) \n",
    "    # fetching moves \n",
    "    legal_moves_san = [board.san(moves) for moves in legal_moves] \n",
    "    # listing moves in SAN \n",
    "    legal_moves_uci = [board.uci(moves) for moves in legal_moves] \n",
    "    # listing moves in UCI \n",
    "\n",
    "    return legal_moves_uci, legal_moves_san"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5f928e032118e78",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T05:30:32.393095Z",
     "start_time": "2024-03-30T05:30:32.377002Z"
    }
   },
   "outputs": [],
   "source": [
    "def ecode_board(board: chess.Board):\n",
    "\n",
    "    board_enc = torch.zeros((12, 8, 8), device = device)\n",
    "    # initialize the encoded board state, (12 -> 6 + 6 types of pieces (black and white), 8 -> vertical grids, 8 -> horizontal grids) \n",
    "    \n",
    "    oh_label = {\n",
    "        'P': 0,\n",
    "        'R': 1,\n",
    "        'N': 2,\n",
    "        'B': 3,\n",
    "        'Q': 4,\n",
    "        'K': 5,\n",
    "        'p': 6,\n",
    "        'r': 7,\n",
    "        'n': 8,\n",
    "        'b': 9,\n",
    "        'q': 10,\n",
    "        'k': 11\n",
    "    }\n",
    "    # translating piece label to the correpond board state index \n",
    "    \n",
    "    for square in chess.SQUARES: \n",
    "    \n",
    "        piece = board.piece_at(square)\n",
    "            \n",
    "        if piece: \n",
    "        # checking if the square holds a piece \n",
    "\n",
    "            board_count = oh_label[str(piece)]\n",
    "            # fetching for the board state idx \n",
    "            row_count, col_count = torch.tensor(divmod(square, 8), device = device) \n",
    "            # fetching for row & column idx \n",
    "            col_count = torch.abs(col_count - 7)\n",
    "            \n",
    "            \n",
    "            board_enc[board_count, row_count, col_count] = 1\n",
    "            # encode the correspond grid with 1 \n",
    "            \n",
    "    return board_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48ebfb1c98dc3a5b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T05:30:32.412923Z",
     "start_time": "2024-03-30T05:30:32.393716Z"
    }
   },
   "outputs": [],
   "source": [
    "def ecode_moves(moves: list):\n",
    "\n",
    "    state = torch.zeros((120, 8, 8), device = device) \n",
    "    # 120 -> max 120 moves \n",
    "    col_dict = {'a': 7, 'b': 6, 'c': 5, 'd': 4, 'e': 3, 'f': 2, 'g': 1, 'h': 0} \n",
    "    # indexing column \n",
    "    for ind, move in enumerate(moves[:120]):\n",
    "        \n",
    "        # fetching for coordinates \n",
    "        o_col = torch.tensor(col_dict[move[0]], device = device)\n",
    "        # o_row = torch.abs(torch.tensor(int(move[1]) - 1, device = device) - 7)\n",
    "        o_row = torch.tensor(int(move[1]) -1, device = device)\n",
    "        e_col = torch.tensor(col_dict[move[2]], device = device)\n",
    "        e_row = torch.tensor(int(move[3]) - 1, device = device)\n",
    "\n",
    "        state[ind, o_row, o_col] = 1\n",
    "        # encode the piece location with 1 \n",
    "        \n",
    "        if move[-1] == 'q': \n",
    "            # q -> promotion, target position = 3 if promotion \n",
    "            state[ind, e_row, e_col] = 3 \n",
    "        else: \n",
    "            state[ind, e_row, e_col] = 2\n",
    "            # standard target positions encoded with 2 \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [2., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 2., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 2., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 2.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [2., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mSystemError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 6\u001B[0m\n\u001B[1;32m      2\u001B[0m uci, san \u001B[38;5;241m=\u001B[39m LMs(state) \n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(ecode_moves(uci)[:\u001B[38;5;241m5\u001B[39m])\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mSystemError\u001B[39;00m\n",
      "\u001B[0;31mSystemError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "state = chess.Board() \n",
    "uci, san = LMs(state) \n",
    "\n",
    "print(ecode_moves(uci)[:5])\n",
    "\n",
    "# raise SystemError \n",
    "# test "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T05:30:42.317064Z",
     "start_time": "2024-03-30T05:30:42.302347Z"
    }
   },
   "id": "2485eee3a11194a5",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40af59a47c5cd37",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T05:30:32.439553Z",
     "start_time": "2024-03-30T05:30:32.439504Z"
    }
   },
   "outputs": [],
   "source": [
    "# penalty system \n",
    "def pan_sys(pred_ind, board_state: chess.Board, legal_uci, legal_san, v, captures):\n",
    "    assert type(board_state) == chess.Board \n",
    "\n",
    "    if pred_ind >= len(legal_uci): \n",
    "        \n",
    "        total_lm_penalty = torch.tensor(0, dtype = torch.float32, device = device)\n",
    "        total_action_penalty = torch.tensor(0, dtype = torch.float32, device = device) \n",
    "        # legal move & choice penalty for choosing illegal moves \n",
    "        move = None \n",
    "        # no move returning \n",
    "        # v_val = None\n",
    "    \n",
    "    else: \n",
    "        # prioritizing capture if a legal move was chose \n",
    "        move = legal_uci[pred_ind]\n",
    "        actionn = legal_san[pred_ind]\n",
    "        action = actionn.replace('x', '').replace('+', '').replace('q', '').replace('#', '').replace('=', '') \n",
    "        # filter out useless symbols \n",
    "    \n",
    "        file = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'] \n",
    "        # columns \n",
    "        s_piece = ['R', 'N', 'B'] \n",
    "        capture = 'x' \n",
    "        # capture notations \n",
    "    \n",
    "        # fetching for the target grid \n",
    "        if 2 < len(action) < 6 and action[0] in file:\n",
    "            action = f'p{action[1:3]}'\n",
    "        if len(actionn) == 2:\n",
    "            action = f'p{actionn}'\n",
    "        elif len(actionn) >= 6:\n",
    "            action = f'p{actionn[2:4]}'\n",
    "        elif (capture in actionn) and (actionn[0] in s_piece) and (actionn[1] in file):\n",
    "            action = actionn[:1] + actionn[2:]\n",
    "        \n",
    "        # indexing columns \n",
    "        col_dict = {'a': t(0), 'b': t(1), 'c': t(2), 'd': t(3), 'e': t(4), 'f': t(5), 'g': t(6), 'h': t(7)}\n",
    "        \n",
    "        # initial rewards for capture \n",
    "        penalty_ = {'p': t(2), 'n': t(4), 'b': t(4), 'r': t(7), 'q': t(10), 'k': t(float('inf'))}\n",
    "    \n",
    "        total_lm_penalty = torch.tensor(0.5, dtype = torch.float32, device = device)\n",
    "        total_action_penalty = torch.tensor(0., dtype = torch.float32, device = device) \n",
    "        # initializing total penalties \n",
    "    \n",
    "        if '#' in actionn:\n",
    "            total_action_penalty = total_action_penalty + 3 \n",
    "            # reward 3 points if checkmate \n",
    "    \n",
    "        base_penalty = 0.5\n",
    "        # setting the base penalty for calculation \n",
    "        \n",
    "        if (capture not in actionn) and captures:\n",
    "            total_action_penalty = total_action_penalty - 0 \n",
    "            # calculating penalty if capturing is in the legal moves but no capture in the choice \n",
    "            # v_val = None\n",
    "    \n",
    "        elif  (capture not in actionn) and (not captures):\n",
    "            total_action_penalty = torch.tensor(0, dtype = torch.float32, device = device) \n",
    "            # calculating penalty if no captures in the legal moves \n",
    "    \n",
    "        else:\n",
    "            try:\n",
    "                # calculating the capture score for each type of piece \n",
    "                cap_loc = action[1:3]\n",
    "                square = (torch.tensor(int(cap_loc[1]), device = device) - 1) * 8 + int(col_dict[cap_loc[0]])\n",
    "                I_piece = action[0].lower() \n",
    "                # self \n",
    "                o_piece = str(board_state.piece_at(square.item())).lower() \n",
    "                # target \n",
    "                refI = penalty_[I_piece]\n",
    "                refO = penalty_[o_piece]\n",
    "                \n",
    "                # prioritize capturing more valuable pieces \n",
    "                if refI < refO:\n",
    "                    mul = (refO - refI) / 2\n",
    "                    penalty_score = base_penalty * refO * mul\n",
    "                elif refI > refO:\n",
    "                    mul = (refI - refO)\n",
    "                    penalty_score = base_penalty * (refO / mul)\n",
    "                elif refI == refO:\n",
    "                    penalty_score = base_penalty\n",
    "                else:\n",
    "                    penalty_score = 0\n",
    "    \n",
    "                total_action_penalty  = total_action_penalty + penalty_score\n",
    "    \n",
    "            except Exception as e:\n",
    "                total_action_penalty = 0\n",
    "    \n",
    "            # v_val = bellman(v) \n",
    "    return total_action_penalty + total_lm_penalty #, move #, v_val \n",
    "    # total reward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac5409a73bf305",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pg_loss(prob, r):\n",
    "    if not prob == 0 or not prob.is_nan():\n",
    "        loss = -torch.sum(torch.log(prob) * r)\n",
    "    else:\n",
    "        loss = None\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b343ba1915ee50",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1326ec8defdff15d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# epsilon greedy choice, ex -> exploration \n",
    "def ep(prob_dist, true): \n",
    "    n = torch.rand(1) \n",
    "    ex = True\n",
    "    if n >= 0.5: \n",
    "        move = torch.argmax(prob_dist, dim = -1) \n",
    "        ex = False\n",
    "    else: \n",
    "        move = torch.randint(0, len(true), (1, prob_dist.size(0))).squeeze() \n",
    "        \n",
    "    return move, ex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e51133eb18c8b85",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# update \n",
    "class renair: \n",
    "    def __init__(self, learning_rate): \n",
    "        \n",
    "        self.dom = cheslermod().to(device) \n",
    "        # model \n",
    "        self.chesleropt = torch.optim.Adam(params=self.dom.parameters(), lr=learning_rate) \n",
    "        # optimizer \n",
    "        self.accurws = [] \n",
    "        # rewards after discount \n",
    "        self.accuprobs = None \n",
    "        # accumulate probabilities \n",
    "        self.gmrws = [] \n",
    "        # raw rewards \n",
    "        self.first = True \n",
    "        \n",
    "    def update(self, stacked_moves, stacked_states, uci, san, caps, boards): \n",
    "        \n",
    "        stigol = self.dom(stacked_moves, stacked_states) \n",
    "        # forward pass \n",
    "        # probs = Categorical(stigol) \n",
    "        inxs, exploration = ep(stigol, uci) \n",
    "        # getting index \n",
    "        zeroth = [0, 1, 2] \n",
    "        # batch idx \n",
    "        \n",
    "        # collecting probabilities and rewards \n",
    "        if self.first: \n",
    "            self.accuprobs = stigol[zeroth, inxs] \n",
    "            self.first = False \n",
    "            \n",
    "        elif not self.first: \n",
    "            self.accuprobs = torch.cat([self.accuprobs, stigol[zeroth, inxs]]) \n",
    "            \n",
    "            \n",
    "        for inx, board, cap in zip(inxs, boards, caps): \n",
    "            \n",
    "            rw = pan_sys(inx, board, uci, san, 0, cap) \n",
    "            self.accurws.append(rw) \n",
    "\n",
    "        return inxs[-1] \n",
    "    \n",
    "    def train(self, γ): \n",
    "        # backpropagate and update \n",
    "        for rw in self.accurws: \n",
    "            self.gmrws.append((rw * γ)) \n",
    "        # discount rewards \n",
    "        \n",
    "        self.gmrws, self.accurws = t(self.gmrws), t(self.accurws) \n",
    "        self.accuprobs = torch.log(self.accuprobs)\n",
    "        # log probs \n",
    "        \n",
    "        loss = -(self.accuprobs * self.gmrws).mean() \n",
    "        # loss calculation \n",
    "        \n",
    "        self.chesleropt.zero_grad() \n",
    "        loss.backward() \n",
    "        self.chesleropt.step() \n",
    "        \n",
    "        self.accurws, self.gmrws = [self.accurws], [self.gmrws] \n",
    "        self.accurws.clear() \n",
    "        self.accuprobs = None \n",
    "        self.gmrws.clear() \n",
    "        self.first = True \n",
    "        # reinitialize params for the next iter \n",
    "        \n",
    "        return loss.detach().item() \n",
    "        \n",
    "renairt = renair(0.0001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f0614e80502391",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as mtpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b10ccdb24ddabd7f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:08:07.500052Z",
     "start_time": "2024-04-06T08:08:07.494002Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(epos):\n",
    "    \n",
    "    def stack(ten, dim = 0): \n",
    "        return torch.stack(ten, dim = dim) \n",
    "    # fast stacking \n",
    "        \n",
    "    epos = range(epos) \n",
    "    losses = [] \n",
    "    c = 0\n",
    "    low_loss = float('inf') \n",
    "    \n",
    "    for epo in tqdm(epos): \n",
    "        \n",
    "        if epo % 20 == 0 and epo != 0:\n",
    "            mtpt.plot(losses)\n",
    "            mtpt.title('Training Losses')\n",
    "            mtpt.xlabel('Epochs')\n",
    "            mtpt.ylabel('Loss')\n",
    "            mtpt.grid(True)\n",
    "            mtpt.show()\n",
    "            \n",
    "        envir = chess.Board() \n",
    "        # initialize the enviroment \n",
    "        init_legal_uci, init_legal_sann = LMs(envir) \n",
    "        # fetching for initial legal moves \n",
    "        init_move = True \n",
    "        \n",
    "        total_moves = 0 \n",
    "        \n",
    "        acc_moves = [ecode_moves(init_legal_uci), ecode_moves(init_legal_uci)] \n",
    "        acc_states = [ecode_board(envir), ecode_board(envir)] \n",
    "        acc_boards = [envir, envir] \n",
    "        acc_caps = [False, False] \n",
    "        # batching inputs \n",
    "        \n",
    "        while True: \n",
    "            \n",
    "            mate = envir.is_checkmate() \n",
    "            draw = envir.is_stalemate() or envir.is_insufficient_material() \n",
    "            fin = mate or draw \n",
    "            # termination \n",
    "            \n",
    "            if fin: \n",
    "                break\n",
    "\n",
    "            legal_uci, legal_sann = LMs(envir) \n",
    "\n",
    "            captures = False \n",
    "            \n",
    "            for legal_san in legal_sann:\n",
    "                if 'x' in legal_san:\n",
    "                    captures = True \n",
    "                    # checking if the move is a capture \n",
    "            \n",
    "            state = ecode_board(envir) \n",
    "            moves = ecode_moves(legal_uci) \n",
    "            # getting encoded board state and legal moves \n",
    "            rand_move = legal_uci[torch.randint(0, len(legal_uci), (1, 1))] \n",
    "            move_rand = chess.Move.from_uci(rand_move) \n",
    "            # choosing a random move if model ouputs a illegal choice \n",
    "            \n",
    "            if init_move: \n",
    "                acc_moves.append(moves) \n",
    "                acc_states.append(state) \n",
    "                acc_boards.append(envir)\n",
    "                acc_caps.append(captures) \n",
    "                init_move = False \n",
    "                # mounting the first move to the batch \n",
    "            else: \n",
    "                acc_moves.pop(0), acc_states.pop(0), acc_boards.pop(0), acc_caps.pop(0) \n",
    "                acc_moves.append(moves) \n",
    "                acc_states.append(state) \n",
    "                acc_boards.append(envir) \n",
    "                acc_caps.append(captures) \n",
    "                # remove the earliest board state (2 moves behind) and append the last board state \n",
    "\n",
    "            cur_moves, cur_states, cur_boards, cur_cap = stack(acc_moves), stack(acc_states), acc_boards, acc_caps \n",
    "            # batching inputs \n",
    "            \n",
    "            pred_move_inx = renairt.update(cur_moves, cur_states, legal_uci, legal_sann, cur_cap, cur_boards) \n",
    "            # getting the move index \n",
    "            \n",
    "            # pushing a random move if the choice illegal, else push the chose move \n",
    "            if not pred_move_inx < len(legal_uci): \n",
    "                envir.push(move_rand) \n",
    "            else: \n",
    "                envir.push(chess.Move.from_uci(legal_uci[pred_move_inx])) \n",
    "        \n",
    "        # 0.9 -> gamma rate, backpropagate \n",
    "        loss = renairt.train(0.9) \n",
    "        losses.append(loss) \n",
    "        \n",
    "        # update weights and bias if loss improved \n",
    "        if loss < low_loss: \n",
    "            dom_state = renairt.dom().state_dict() \n",
    "            opt_state = renairt.chesleropt().state_dict() \n",
    "            \n",
    "            torch.save(dom_state, '') \n",
    "            torch.save(opt_state, '') \n",
    "            low_loss = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2b31cdd8917a0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270aeda8b4fe3bdb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
