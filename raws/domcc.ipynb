{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.280392Z",
     "start_time": "2024-03-29T04:47:00.278598Z"
    }
   },
   "id": "3a0e3e14f5762549",
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.396074Z",
     "start_time": "2024-03-29T04:47:00.290955Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import chess \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.419802Z",
     "start_time": "2024-03-29T04:47:00.397785Z"
    }
   },
   "id": "95fa2cb59fc98567",
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class kcolbvonc(nn.Module):\n",
    "    def __init__(self, ic, oc, ks, st, pd, active: bool = True, ip:bool = True):\n",
    "        super(kcolbvonc, self).__init__()\n",
    "        \n",
    "        self.ip = ip\n",
    "        self.tive = active\n",
    "        self.kcolb = self.kcolbkcolb(ic, oc, ks, st, pd)\n",
    "        \n",
    "    def kcolbkcolb(self, ic, oc, ks, st, pd):\n",
    "        \n",
    "        if not self.tive:\n",
    "            \n",
    "            kcolbconv = nn.Sequential(\n",
    "                nn.Conv2d(ic, oc, ks, st, pd), \n",
    "                nn.BatchNorm2d(oc), \n",
    "            )\n",
    "        \n",
    "        else:\n",
    "\n",
    "            kcolbconv = nn.Sequential(\n",
    "                nn.Conv2d(ic, oc, ks, st, pd), \n",
    "                nn.BatchNorm2d(oc), \n",
    "                nn.LeakyReLU(inplace = self.ip)\n",
    "            )\n",
    "            \n",
    "        return kcolbconv\n",
    "    \n",
    "    def forward(self, idk) -> torch.Tensor:\n",
    "        \n",
    "        return self.kcolb(idk)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.436098Z",
     "start_time": "2024-03-29T04:47:00.420332Z"
    }
   },
   "id": "5a663bbe6c07dd1c",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class laud(nn.Module):\n",
    "    def __init__(self, ic, oc, ks, st, pd, nnn: int, jump: bool = True):\n",
    "        super(laud, self).__init__()\n",
    "        \n",
    "        self.ic = ic\n",
    "        self.oc = oc\n",
    "        self.ks = ks\n",
    "        self.st = st\n",
    "        self.pd = pd\n",
    "        self.j = jump\n",
    "        self.nnn = nnn\n",
    "        self.nc: int = 0\n",
    "        \n",
    "        self.reyal = self.laudreyal()\n",
    "        self.matcher = kcolbvonc(ic, oc, 1, 1, 0, active = False)\n",
    "        self.smatcher = nn.AdaptiveMaxPool2d((8, 8))\n",
    "        \n",
    "    def forward(self, idk):\n",
    "        \n",
    "        logitnotgood = idk\n",
    "        \n",
    "        for layer in self.reyal:\n",
    "            logitnotgood = layer(logitnotgood)\n",
    "        \n",
    "        if self.j and (self.ic != self.oc):\n",
    "            \n",
    "            idk = self.matcher(idk)\n",
    "            logitnotgood = self.smatcher(logitnotgood)\n",
    "            \n",
    "            logitgood = idk + logitnotgood\n",
    "                        \n",
    "        elif self.j and (self.ic == self.oc):\n",
    "\n",
    "            logitnotgood = self.smatcher(logitnotgood)\n",
    "            \n",
    "            logitgood = idk + logitnotgood\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            logitgood = logitnotgood\n",
    "            print('using a residual block builder to build a conv block? are you outta your mind...h/e heres your tensor')\n",
    "\n",
    "        return logitgood\n",
    "\n",
    "    def laudreyal(self):\n",
    "            \n",
    "        reyal = nn.ModuleList()\n",
    "        self.nc = self.ic\n",
    "        \n",
    "        for nnnn in range(self.nnn):\n",
    "            \n",
    "            ncc = self.ic * (nnnn + 2)\n",
    "            \n",
    "            rayal = kcolbvonc(self.nc, ncc, self.ks, self.st, self.pd)\n",
    "\n",
    "            reyal.append(rayal)\n",
    "            self.nc = ncc\n",
    "\n",
    "\n",
    "        rayalo = kcolbvonc(self.nc, self.oc, self.ks, self.st, self.pd)\n",
    "\n",
    "        reyal.append(rayalo)\n",
    "        \n",
    "        return reyal"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.451927Z",
     "start_time": "2024-03-29T04:47:00.436889Z"
    }
   },
   "id": "4454950f4148c566",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dummyo = torch.rand((2, 12, 8, 8), device = device)\n",
    "dummyoo = torch.rand((2, 120, 8, 8), device = device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.472423Z",
     "start_time": "2024-03-29T04:47:00.452687Z"
    }
   },
   "id": "1a93315eda206be3",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class cheslermod(nn.Module):\n",
    "    def __init__(self): \n",
    "        super(cheslermod, self).__init__()\n",
    "        \n",
    "        self.alin = nn.Sequential(\n",
    "            laud(ic = 120, oc = 256, ks = 2, st = 1, pd = 1, nnn = 2), \n",
    "            laud(ic = 256, oc = 128, ks = 2, st = 1, pd = 1, nnn = 2), \n",
    "        )\n",
    "        \n",
    "        self.stein = nn.Sequential(\n",
    "            laud(ic = 12, oc = 128, ks = 2, st = 1, pd = 1, nnn = 2),\n",
    "        )\n",
    "        \n",
    "        self.after = nn.Sequential(\n",
    "            laud(ic = 128, oc = 32, ks = 2, st = 1, pd = 1, nnn = 2), \n",
    "            nn.Flatten(), \n",
    "            self.lfter(2048, 1024, True), \n",
    "            self.lfter(1024, 512, True), \n",
    "            self.lfter(512, 120, False)\n",
    "        )\n",
    "        \n",
    "    def forward(self, oo, o):\n",
    "        \n",
    "        i = self.alin(oo)\n",
    "        ii = self.stein(o)\n",
    "        \n",
    "        z = i + ii\n",
    "        \n",
    "        zz = self.after(z)\n",
    "        \n",
    "        return zz\n",
    "    \n",
    "    @staticmethod\n",
    "    def lfter(ic, oc, nfl):\n",
    "        \n",
    "        if nfl:\n",
    "            \n",
    "            l = nn.Sequential(\n",
    "                nn.Linear(ic, oc), \n",
    "                nn.BatchNorm1d(oc), \n",
    "                nn.LeakyReLU(inplace = True)\n",
    "            )        \n",
    "        \n",
    "        else:\n",
    "\n",
    "            l = nn.Sequential(\n",
    "                nn.Linear(ic, oc),\n",
    "                nn.Softmax(dim = -1)\n",
    "            )\n",
    "            \n",
    "        return l"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.483511Z",
     "start_time": "2024-03-29T04:47:00.472854Z"
    }
   },
   "id": "edbeb2e21cd6646f",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cheslerdom = cheslermod().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.532948Z",
     "start_time": "2024-03-29T04:47:00.483997Z"
    }
   },
   "id": "b77329caab244a13",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 120])\n",
      "tensor(1.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([0.0082, 0.0155, 0.0065, 0.0119, 0.0074, 0.0062, 0.0141, 0.0190, 0.0057,\n",
      "        0.0080, 0.0047, 0.0109, 0.0055, 0.0130, 0.0111, 0.0052, 0.0097, 0.0145,\n",
      "        0.0124, 0.0071, 0.0096, 0.0078, 0.0137, 0.0066, 0.0074, 0.0038, 0.0055,\n",
      "        0.0115, 0.0051, 0.0080, 0.0042, 0.0106, 0.0087, 0.0157, 0.0063, 0.0069,\n",
      "        0.0155, 0.0126, 0.0061, 0.0083, 0.0073, 0.0103, 0.0096, 0.0074, 0.0051,\n",
      "        0.0049, 0.0047, 0.0039, 0.0064, 0.0093, 0.0033, 0.0092, 0.0049, 0.0107,\n",
      "        0.0037, 0.0084, 0.0098, 0.0071, 0.0111, 0.0052, 0.0068, 0.0078, 0.0096,\n",
      "        0.0123, 0.0039, 0.0062, 0.0075, 0.0096, 0.0076, 0.0068, 0.0075, 0.0042,\n",
      "        0.0069, 0.0090, 0.0165, 0.0063, 0.0064, 0.0059, 0.0048, 0.0068, 0.0087,\n",
      "        0.0025, 0.0105, 0.0099, 0.0110, 0.0068, 0.0073, 0.0138, 0.0103, 0.0104,\n",
      "        0.0087, 0.0101, 0.0089, 0.0138, 0.0068, 0.0065, 0.0104, 0.0119, 0.0085,\n",
      "        0.0063, 0.0077, 0.0087, 0.0048, 0.0129, 0.0094, 0.0066, 0.0036, 0.0124,\n",
      "        0.0035, 0.0053, 0.0101, 0.0059, 0.0081, 0.0070, 0.0093, 0.0058, 0.0128,\n",
      "        0.0073, 0.0053, 0.0052], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(7, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = cheslerdom(dummyoo, dummyo)\n",
    "print(a.shape)\n",
    "print(sum(a[-1]))\n",
    "print(a[0])\n",
    "print(torch.argmax(a[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.540661Z",
     "start_time": "2024-03-29T04:47:00.533581Z"
    }
   },
   "id": "17ced9a114796cb1",
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def t(tensor):\n",
    "    return torch.tensor(tensor, device = device, dtype = torch.float16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.550947Z",
     "start_time": "2024-03-29T04:47:00.541206Z"
    }
   },
   "id": "5b59c4cc70009d7e",
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def LMs(board: chess.Board):\n",
    "\n",
    "    legal_moves = list(board.legal_moves)\n",
    "    legal_moves_san = [board.san(moves) for moves in legal_moves]\n",
    "    legal_moves_uci = [board.uci(moves) for moves in legal_moves]\n",
    "\n",
    "    return legal_moves_uci, legal_moves_san"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.566029Z",
     "start_time": "2024-03-29T04:47:00.552195Z"
    }
   },
   "id": "de66e5c4ca961e59",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def ecode_board(board: chess.Board):\n",
    "\n",
    "    board_enc = torch.zeros((12, 8, 8), device = device)\n",
    "\n",
    "    oh_label = {\n",
    "        'P': 0,\n",
    "        'R': 1,\n",
    "        'N': 2,\n",
    "        'B': 3,\n",
    "        'Q': 4,\n",
    "        'K': 5,\n",
    "        'p': 6,\n",
    "        'r': 7,\n",
    "        'n': 8,\n",
    "        'b': 9,\n",
    "        'q': 10,\n",
    "        'k': 11\n",
    "    }\n",
    "\n",
    "    for square in chess.SQUARES:\n",
    "\n",
    "        piece = board.piece_at(square)\n",
    "\n",
    "        if piece:\n",
    "\n",
    "            board_count = oh_label[str(piece)]\n",
    "            row_count, col_count = torch.tensor(divmod(square, 8), device = device)\n",
    "            col_count = torch.abs(col_count - 7)\n",
    "\n",
    "            board_enc[board_count, row_count, col_count] = 1\n",
    "            \n",
    "    return board_enc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.586210Z",
     "start_time": "2024-03-29T04:47:00.566662Z"
    }
   },
   "id": "f5f928e032118e78",
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def ecode_moves(moves: list):\n",
    "\n",
    "    state = torch.zeros((120, 8, 8), device = device)\n",
    "    # col_dict = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7}\n",
    "    col_dict = {'a': 7, 'b': 6, 'c': 5, 'd': 4, 'e': 3, 'f': 2, 'g': 1, 'h': 0}\n",
    "    for ind, move in enumerate(moves[:120]):\n",
    "\n",
    "        o_col = torch.tensor(col_dict[move[0]], device = device)\n",
    "        # o_row = torch.abs(torch.tensor(int(move[1]) - 1, device = device) - 7)\n",
    "        o_row = torch.tensor(int(move[1]) -1, device = device)\n",
    "        e_col = torch.tensor(col_dict[move[2]], device = device)\n",
    "        e_row = torch.tensor(int(move[3]) - 1, device = device)\n",
    "\n",
    "        state[ind, o_row, o_col] = 1\n",
    "\n",
    "        if move[-1] == 'q':\n",
    "            state[ind, e_row, e_col] = 3\n",
    "        else:\n",
    "            state[ind, e_row, e_col] = 2\n",
    "\n",
    "    return state"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.601778Z",
     "start_time": "2024-03-29T04:47:00.587042Z"
    }
   },
   "id": "48ebfb1c98dc3a5b",
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def pan_sys(pred_ind, board_state: chess.Board, legal_uci, legal_san, v, captures):\n",
    "    assert type(board_state) == chess.Board \n",
    "\n",
    "    if pred_ind >= len(legal_uci): \n",
    "        \n",
    "        total_lm_penalty = torch.tensor(0, dtype = torch.float32, device = device)\n",
    "        total_action_penalty = torch.tensor(0, dtype = torch.float32, device = device)\n",
    "        move = None\n",
    "        # v_val = None\n",
    "    \n",
    "    else:\n",
    "        move = legal_uci[pred_ind]\n",
    "        actionn = legal_san[pred_ind]\n",
    "        action = actionn.replace('x', '').replace('+', '').replace('q', '').replace('#', '').replace('=', '')\n",
    "    \n",
    "        file = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "        s_piece = ['R', 'N', 'B']\n",
    "        capture = 'x'\n",
    "    \n",
    "    \n",
    "        if 2 < len(action) < 6 and action[0] in file:\n",
    "            action = f'p{action[1:3]}'\n",
    "        if len(actionn) == 2:\n",
    "            action = f'p{actionn}'\n",
    "        elif len(actionn) >= 6:\n",
    "            action = f'p{actionn[2:4]}'\n",
    "        elif (capture in actionn) and (actionn[0] in s_piece) and (actionn[1] in file):\n",
    "            action = actionn[:1] + actionn[2:]\n",
    "    \n",
    "        col_dict = {'a': t(0), 'b': t(1), 'c': t(2), 'd': t(3), 'e': t(4), 'f': t(5), 'g': t(6), 'h': t(7)}\n",
    "    \n",
    "        penalty_ = {'p': t(2), 'n': t(4), 'b': t(4), 'r': t(7), 'q': t(10), 'k': t(float('inf'))}\n",
    "    \n",
    "        total_lm_penalty = torch.tensor(0.5, dtype = torch.float32, device = device)\n",
    "        total_action_penalty = torch.tensor(0., dtype = torch.float32, device = device)\n",
    "    \n",
    "        if '#' in actionn:\n",
    "            total_action_penalty = total_action_penalty + 3\n",
    "    \n",
    "        base_penalty = 0.5\n",
    "    \n",
    "        if (capture not in actionn) and captures:\n",
    "            total_action_penalty = total_action_penalty - 0\n",
    "            # v_val = None\n",
    "    \n",
    "        elif  (capture not in actionn) and (not captures):\n",
    "            total_action_penalty = torch.tensor(0, dtype = torch.float32, device = device)\n",
    "    \n",
    "        else:\n",
    "            try:\n",
    "                cap_loc = action[1:3]\n",
    "                square = (torch.tensor(int(cap_loc[1]), device = device) - 1) * 8 + int(col_dict[cap_loc[0]])\n",
    "                I_piece = action[0].lower()\n",
    "                o_piece = str(board_state.piece_at(square.item())).lower()\n",
    "                refI = penalty_[I_piece]\n",
    "                refO = penalty_[o_piece]\n",
    "    \n",
    "                if refI < refO:\n",
    "                    mul = (refO - refI) / 2\n",
    "                    penalty_score = base_penalty * refO * mul\n",
    "                elif refI > refO:\n",
    "                    mul = (refI - refO)\n",
    "                    penalty_score = base_penalty * (refO / mul)\n",
    "                elif refI == refO:\n",
    "                    penalty_score = base_penalty\n",
    "                else:\n",
    "                    penalty_score = 0\n",
    "    \n",
    "                total_action_penalty  = total_action_penalty + penalty_score\n",
    "    \n",
    "            except Exception as e:\n",
    "                total_action_penalty = 0\n",
    "    \n",
    "            # v_val = bellman(v)\n",
    "    return total_action_penalty + total_lm_penalty #, move #, v_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.714055Z",
     "start_time": "2024-03-29T04:47:00.602398Z"
    }
   },
   "id": "f40af59a47c5cd37",
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def pg_loss(prob, r):\n",
    "    if not prob == 0 or not prob.is_nan():\n",
    "        loss = -torch.sum(torch.log(prob) * r)\n",
    "    else:\n",
    "        loss = None\n",
    "\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.728942Z",
     "start_time": "2024-03-29T04:47:00.714626Z"
    }
   },
   "id": "eaac5409a73bf305",
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.746474Z",
     "start_time": "2024-03-29T04:47:00.729388Z"
    }
   },
   "id": "10b343ba1915ee50",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def ep(prob_dist, true): \n",
    "    n = torch.rand(1) \n",
    "    ex = True\n",
    "    if n >= 0.5: \n",
    "        move = torch.argmax(prob_dist, dim = -1) \n",
    "        ex = False\n",
    "    else: \n",
    "        move = torch.randint(0, len(true), (1, prob_dist.size(0))).squeeze() \n",
    "        \n",
    "    return move, ex "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.765212Z",
     "start_time": "2024-03-29T04:47:00.747005Z"
    }
   },
   "id": "1326ec8defdff15d",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class renair: \n",
    "    def __init__(self, learning_rate): \n",
    "        \n",
    "        self.dom = cheslermod().to(device)\n",
    "        self.chesleropt = torch.optim.Adam(params=self.dom.parameters(), lr=learning_rate)\n",
    "        self.accurws = [] \n",
    "        self.accuprobs = None \n",
    "        self.gmrws = []\n",
    "        self.first = True \n",
    "        \n",
    "    def update(self, stacked_moves, stacked_states, uci, san, caps, boards): \n",
    "        \n",
    "        stigol = self.dom(stacked_moves, stacked_states) \n",
    "        # probs = Categorical(stigol) \n",
    "        inxs, exploration = ep(stigol, uci) \n",
    "        zeroth = [0, 1, 2] \n",
    "        \n",
    "        if self.first: \n",
    "            self.accuprobs = stigol[zeroth, inxs] \n",
    "            self.first = False \n",
    "            \n",
    "        elif not self.first: \n",
    "            self.accuprobs = torch.cat([self.accuprobs, stigol[zeroth, inxs]]) \n",
    "            \n",
    "            \n",
    "        for inx, board, cap in zip(inxs, boards, caps): \n",
    "            \n",
    "            rw = pan_sys(inx, board, uci, san, 0, cap) \n",
    "            self.accurws.append(rw) \n",
    "\n",
    "        return inxs[-1] \n",
    "    \n",
    "    def train(self, γ): \n",
    "        \n",
    "        for rw in self.accurws: \n",
    "            self.gmrws.append((rw * γ)) \n",
    "        \n",
    "        self.gmrws, self.accurws = t(self.gmrws), t(self.accurws) \n",
    "        self.accuprobs = torch.log(self.accuprobs)\n",
    "        \n",
    "        loss = -(self.accuprobs * self.gmrws).mean() \n",
    "        \n",
    "        self.chesleropt.zero_grad() \n",
    "        loss.backward() \n",
    "        self.chesleropt.step() \n",
    "        \n",
    "        self.accurws, self.gmrws = [self.accurws], [self.gmrws] \n",
    "        self.accurws.clear() \n",
    "        self.accuprobs = None \n",
    "        self.gmrws.clear() \n",
    "        self.first = True \n",
    "        \n",
    "        return loss.detach().item() \n",
    "        \n",
    "renairt = renair(0.0001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.831636Z",
     "start_time": "2024-03-29T04:47:00.765710Z"
    }
   },
   "id": "6e51133eb18c8b85",
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as mtpt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.840088Z",
     "start_time": "2024-03-29T04:47:00.836325Z"
    }
   },
   "id": "89f0614e80502391",
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train(epos):\n",
    "    \n",
    "    def stack(ten, dim = 0): \n",
    "        return torch.stack(ten, dim = dim) \n",
    "        \n",
    "    epos = range(epos) \n",
    "    losses = []\n",
    "    c = 0\n",
    "    low_loss = float('inf')\n",
    "    \n",
    "    for epo in tqdm(epos): \n",
    "        \n",
    "        if epo % 20 == 0 and epo != 0:\n",
    "            mtpt.plot(losses)\n",
    "            mtpt.title('Training Losses')\n",
    "            mtpt.xlabel('Epochs')\n",
    "            mtpt.ylabel('Loss')\n",
    "            mtpt.grid(True)\n",
    "            mtpt.show()\n",
    "            \n",
    "        envir = chess.Board()\n",
    "        init_legal_uci, init_legal_sann = LMs(envir)\n",
    "        init_move = True \n",
    "        \n",
    "        total_moves = 0 \n",
    "        \n",
    "        acc_moves = [ecode_moves(init_legal_uci), ecode_moves(init_legal_uci)] \n",
    "        acc_states = [ecode_board(envir), ecode_board(envir)] \n",
    "        acc_boards = [envir, envir] \n",
    "        acc_caps = [False, False]\n",
    "        \n",
    "        while True: \n",
    "            \n",
    "            mate = envir.is_checkmate() \n",
    "            draw = envir.is_stalemate() or envir.is_insufficient_material() \n",
    "            fin = mate or draw \n",
    "            \n",
    "            if fin: \n",
    "                break\n",
    "\n",
    "            legal_uci, legal_sann = LMs(envir) \n",
    "\n",
    "            captures = False \n",
    "            \n",
    "            for legal_san in legal_sann:\n",
    "                if 'x' in legal_san:\n",
    "                    captures = True \n",
    "            \n",
    "            state = ecode_board(envir) \n",
    "            moves = ecode_moves(legal_uci) \n",
    "            rand_move = legal_uci[torch.randint(0, len(legal_uci), (1, 1))] \n",
    "            move_rand = chess.Move.from_uci(rand_move) \n",
    "            \n",
    "            if init_move: \n",
    "                acc_moves.append(moves) \n",
    "                acc_states.append(state) \n",
    "                acc_boards.append(envir)\n",
    "                acc_caps.append(captures) \n",
    "                init_move = False \n",
    "            else: \n",
    "                acc_moves.pop(0), acc_states.pop(0), acc_boards.pop(0), acc_caps.pop(0) \n",
    "                acc_moves.append(moves) \n",
    "                acc_states.append(state) \n",
    "                acc_boards.append(envir) \n",
    "                acc_caps.append(captures) \n",
    "\n",
    "            cur_moves, cur_states, cur_boards, cur_cap = stack(acc_moves), stack(acc_states), acc_boards, acc_caps \n",
    "            \n",
    "            pred_move_inx = renairt.update(cur_moves, cur_states, legal_uci, legal_sann, cur_cap, cur_boards) \n",
    "            \n",
    "            if not pred_move_inx < len(legal_uci): \n",
    "                envir.push(move_rand) \n",
    "            else: \n",
    "                envir.push(chess.Move.from_uci(legal_uci[pred_move_inx])) \n",
    "                \n",
    "        loss = renairt.train(0.9) \n",
    "        losses.append(loss) \n",
    "        \n",
    "        if loss < low_loss: \n",
    "            dom_state = renairt.dom().state_dict() \n",
    "            opt_state = renairt.chesleropt().state_dict() \n",
    "            \n",
    "            torch.save(dom_state, '/run/media/ikase/LinuSat/weiii/chesler/dom.pth') \n",
    "            torch.save(opt_state, '/run/media/ikase/LinuSat/weiii/chesler/opt.pth') \n",
    "            low_loss = loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:00.859779Z",
     "start_time": "2024-03-29T04:47:00.840861Z"
    }
   },
   "id": "b10ccdb24ddabd7f",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cheslermod.forward() missing 2 required positional arguments: 'oo' and 'o'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[83], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[82], line 80\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(epos)\u001B[0m\n\u001B[1;32m     77\u001B[0m losses\u001B[38;5;241m.\u001B[39mappend(loss) \n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m loss \u001B[38;5;241m<\u001B[39m low_loss: \n\u001B[0;32m---> 80\u001B[0m     dom_state \u001B[38;5;241m=\u001B[39m \u001B[43mrenairt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdom\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mstate_dict() \n\u001B[1;32m     81\u001B[0m     opt_state \u001B[38;5;241m=\u001B[39m renairt\u001B[38;5;241m.\u001B[39mchesleropt()\u001B[38;5;241m.\u001B[39mstate_dict() \n\u001B[1;32m     83\u001B[0m     torch\u001B[38;5;241m.\u001B[39msave(dom_state, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/run/media/ikase/LinuSat/weiii/chesler/dom.pth\u001B[39m\u001B[38;5;124m'\u001B[39m) \n",
      "File \u001B[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mTypeError\u001B[0m: cheslermod.forward() missing 2 required positional arguments: 'oo' and 'o'"
     ]
    }
   ],
   "source": [
    "train(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:04.507309Z",
     "start_time": "2024-03-29T04:47:00.860217Z"
    }
   },
   "id": "fe99e412520d22c1",
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T04:47:04.507892Z",
     "start_time": "2024-03-29T04:47:04.507839Z"
    }
   },
   "id": "6a2b31cdd8917a0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "270aeda8b4fe3bdb",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
